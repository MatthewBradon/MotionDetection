{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2 # The OpenCV library; install using `pip install opencv-contrib-python`\n",
    "import numpy as np # Helpful when working with arrays; install using `pip install numpy`\n",
    "from matplotlib import pyplot as plt # Good for graphing; install using `pip install matplotlib`\n",
    "from matplotlib import image as image\n",
    "import easygui # An easy-to-use file-picker; pip install easygui (mac not supported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(frame1, frame2, kernel=np.array((9,9), dtype=np.uint8)):\n",
    "    \n",
    "    frame_diff = cv2.subtract(frame2, frame1)\n",
    "\n",
    "    # blur the frame difference\n",
    "    frame_diff = cv2.medianBlur(frame_diff, 3)\n",
    "    \n",
    "    mask = cv2.adaptiveThreshold(frame_diff, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 3)\n",
    "\n",
    "    mask = cv2.medianBlur(mask, 3)\n",
    "\n",
    "    # morphological operations\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_detections(mask, thresh=400):\n",
    "    # get mask contours\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_TC89_L1)\n",
    "    detections = []\n",
    "    for cnt in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        area = w*h\n",
    "        if area > thresh: \n",
    "            detections.append([x,y,x+w,y+h, area])\n",
    "\n",
    "    return np.array(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
=======
   "execution_count": 1,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_contained_bboxes(boxes):\n",
    "    check_array = np.array([True, True, False, False])\n",
    "    keep = list(range(0, len(boxes)))\n",
    "    for i in keep: # range(0, len(bboxes)):\n",
    "        for j in range(0, len(boxes)):\n",
    "            # check if box j is completely contained in box i\n",
    "            if np.all((np.array(boxes[j]) >= np.array(boxes[i])) == check_array):\n",
    "                try:\n",
    "                    keep.remove(j)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "    return keep\n",
    "\n",
    "\n",
    "def non_max_suppression(boxes, scores, threshold=1e-1):\n",
    "    # Sort the boxes by score in descending order\n",
    "    boxes = boxes[np.argsort(scores)[::-1]]\n",
    "\n",
    "    # remove all contained bounding boxes and get ordered index\n",
    "    order = remove_contained_bboxes(boxes)\n",
    "\n",
    "    keep = []\n",
    "    while order:\n",
    "        i = order.pop(0)\n",
    "        keep.append(i)\n",
    "        for j in order:\n",
    "            # Calculate the IoU between the two boxes\n",
    "            intersection = max(0, min(boxes[i][2], boxes[j][2]) - max(boxes[i][0], boxes[j][0])) * \\\n",
    "                           max(0, min(boxes[i][3], boxes[j][3]) - max(boxes[i][1], boxes[j][1]))\n",
    "            union = (boxes[i][2] - boxes[i][0]) * (boxes[i][3] - boxes[i][1]) + \\\n",
    "                    (boxes[j][2] - boxes[j][0]) * (boxes[j][3] - boxes[j][1]) - intersection\n",
    "            iou = intersection / union\n",
    "\n",
    "            # Remove boxes with IoU greater than the threshold\n",
    "            if iou > threshold:\n",
    "                order.remove(j)\n",
    "                \n",
    "    return boxes[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detections(frame1, frame2, bbox_thresh=400, nms_thresh=1e-3, mask_kernel=np.array((9,9), dtype=np.uint8)):\n",
    "    # get image mask for moving pixels\n",
    "    mask = get_mask(frame1, frame2, mask_kernel)\n",
    "\n",
    "    # get initially proposed detections from contours\n",
    "    detections = get_contour_detections(mask, bbox_thresh)\n",
    "    \n",
    "    # Check if detections are not empty and have the expected shape\n",
    "    if detections is None or len(detections) == 0:\n",
    "        return np.array([])  # Return an empty array if there are no detections\n",
    "    \n",
    "    # Make sure detections is a 2D array\n",
    "    detections = np.atleast_2d(detections)\n",
    "    \n",
    "    # separate bboxes and scores\n",
    "    bboxes = detections[:, :4]  # First 4 columns should be bounding boxes\n",
    "    scores = detections[:, -1]  # Last column should be scores\n",
    "\n",
    "    # perform Non-Maximal Suppression on initial detections\n",
    "    return non_max_suppression(bboxes, scores, nms_thresh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('Images/traffic.mp4')\n",
    "\n",
    "# Compute motion mask\n",
    "kernel = np.array((9, 9), dtype=np.uint8)\n",
    "\n",
    "while True:\n",
    "    ret, frame1 = video.read()\n",
    "    ret, frame2 = video.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Make a copy of the original colored frame for drawing rectangles\n",
    "    display_frame = frame1.copy()\n",
    "    \n",
    "    # Convert frames to grayscale for motion detection\n",
    "    frame1_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Compute motion ma\n",
    "\n",
    "    \n",
    "    detections = get_detections(frame1_gray, frame2_gray, bbox_thresh=400, nms_thresh=1e-3, mask_kernel=kernel)\n",
    "    \n",
    "    # Draw rectangles around detected objects\n",
    "    for x1, y1, x2, y2 in detections:\n",
    "        cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "    # Display the frame with rectangles\n",
    "    cv2.imshow('frame', display_frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 9,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('Images/traffic.mp4')\n",
    "\n",
    "# Compute motion mask\n",
    "kernel = np.array((9, 9), dtype=np.uint8)\n",
    "\n",
    "while True:\n",
    "    ret, frame1 = video.read()\n",
    "    ret, frame2 = video.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Make a copy of the original colored frame for drawing rectangles\n",
    "    display_frame = frame1.copy()\n",
    "    \n",
    "    # Convert frames to grayscale for motion detection\n",
    "    frame1_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Compute motion mask\n",
    "    mask = get_mask(frame1_gray, frame2_gray, kernel)\n",
    "    detections = get_contour_detections(mask)\n",
    "    \n",
    "    # Draw green rectangles around detected objects on the colored frame\n",
    "    for x1, y1, x2, y2, _ in detections:\n",
    "        cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "    # Display the frame with rectangles\n",
    "    cv2.imshow('frame', display_frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
<<<<<<< Updated upstream
    "cv2.destroyAllWindows()\n",
    "video.release()\n"
=======
    "\n",
    "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        boxes = []\n",
    "        scores = []\n",
    "        detected_centers = []\n",
    "        \n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) > self.min_contour_area:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                aspect_ratio = w / h\n",
    "                if 0.4 < aspect_ratio < 2.5:\n",
    "                    confidence = min(cv2.contourArea(contour) / 2000.0, 1.0)\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    scores.append(confidence)\n",
    "                    detected_centers.append(np.array([[x + w / 2], [y + h / 2]], dtype=np.float32))\n",
    "\n",
    "        if boxes:\n",
    "            keep_indices = non_max_suppression(boxes, scores, 0.1)\n",
    "            boxes = [boxes[i] for i in keep_indices]\n",
    "            scores = [scores[i] for i in keep_indices]\n",
    "            detected_centers = [detected_centers[i] for i in keep_indices]\n",
    "\n",
    "        self.update_tracked_objects(detected_centers, boxes, scores)\n",
    "\n",
    "        for box, score in zip(boxes, scores):\n",
    "            x, y, w, h = box\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'{score:.2f}', (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        for obj_id, data in self.tracked_objects.items():\n",
    "            path = data['path']\n",
    "            color = self.track_colors[obj_id]\n",
    "\n",
    "            for i in range(1, len(path)):\n",
    "                alpha = i / len(path)\n",
    "                thickness = int(alpha * 3) + 1\n",
    "                cv2.line(frame, tuple(path[i - 1].astype(int)), tuple(path[i].astype(int)), color, thickness)\n",
    "\n",
    "            predicted = data['kf'].predict()\n",
    "            x, y = int(predicted[0]), int(predicted[1])\n",
    "            cv2.circle(frame, (x, y), 5, color, -1)\n",
    "            cv2.putText(frame, f'ID {obj_id}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        return frame, fg_mask, road_mask\n",
    "\n",
    "    def process_video(self, video_path):\n",
    "        \"\"\"\n",
    "        Process the video frame by frame.\n",
    "        \"\"\"\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open video\")\n",
    "            return\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            processed_frame, fg_mask, road_mask = self.process_frame(frame)\n",
    "\n",
    "            cv2.imshow('Road Mask', road_mask)\n",
    "            cv2.imshow('Foreground Mask', fg_mask)\n",
    "            cv2.imshow('Tracking', processed_frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "processor = VideoProcessor()\n",
    "processor.process_video('Images/traffic2.mp4')"
>>>>>>> Stashed changes
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "version": "3.11.3"
=======
   "version": "3.12.4"
>>>>>>> Stashed changes
=======
   "version": "3.12.4"
>>>>>>> Stashed changes
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
