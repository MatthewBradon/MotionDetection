{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "def non_max_suppression(boxes, scores, threshold):\n",
    "    \"\"\"Apply Non-Maximum Suppression\"\"\"\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    boxes = np.array(boxes, dtype=np.float32)\n",
    "    pick = []\n",
    "    \n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 0] + boxes[:, 2]\n",
    "    y2 = boxes[:, 1] + boxes[:, 3]\n",
    "    \n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(scores)\n",
    "    \n",
    "    while len(idxs) > 0:\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        \n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        \n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        \n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        \n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > threshold)[0])))\n",
    "    \n",
    "    return pick\n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self):\n",
    "        self.mog = cv2.createBackgroundSubtractorMOG2(\n",
    "            history=1000,\n",
    "            varThreshold=16,\n",
    "            detectShadows=True\n",
    "        )\n",
    "        \n",
    "        self.min_contour_area = 200\n",
    "        self.max_trace_length = 50\n",
    "        self.tracks = {}\n",
    "        self.track_colors = {}\n",
    "        self.next_track_id = 0\n",
    "        self.max_tracking_distance = 70\n",
    "        \n",
    "        # NMS parameters\n",
    "        self.nms_threshold = 0.3\n",
    "        self.detection_confidence_threshold = 0.5\n",
    "        \n",
    "        self.frames_until_cleanup = 10\n",
    "        self.track_activity = {}\n",
    "        self.frame_dimensions = None\n",
    "        self.margin = 20\n",
    "        \n",
    "        self.lower_bound = np.array([0, 0, 0])\n",
    "        self.upper_bound = np.array([180, 255, 255])\n",
    "        \n",
    "        self.min_area = 10000\n",
    "        self.dilate_kernel = np.ones((5,5), np.uint8)\n",
    "        self.road_mask = None\n",
    "\n",
    "        self.temporal_buffer = deque(maxlen=5) \n",
    "\n",
    "        \n",
    "        cv2.namedWindow('Road Mask Controls')\n",
    "        cv2.createTrackbar('Hue Min', 'Road Mask Controls', 103, 180, self.nothing)\n",
    "        cv2.createTrackbar('Hue Max', 'Road Mask Controls', 180, 180, self.nothing)\n",
    "        cv2.createTrackbar('Sat Min', 'Road Mask Controls', 0, 255, self.nothing)\n",
    "        cv2.createTrackbar('Sat Max', 'Road Mask Controls', 255, 255, self.nothing)\n",
    "        cv2.createTrackbar('Val Min', 'Road Mask Controls', 0, 255, self.nothing)\n",
    "        cv2.createTrackbar('Val Max', 'Road Mask Controls', 255, 255, self.nothing)\n",
    "        cv2.createTrackbar('Min Area', 'Road Mask Controls', 10000, 20000, self.nothing)\n",
    "        cv2.createTrackbar('Dilate', 'Road Mask Controls', 20, 20, self.nothing)\n",
    "        cv2.createTrackbar('Min Vehicle Size', 'Road Mask Controls', 200, 1000, self.nothing)\n",
    "        cv2.createTrackbar('Detection Sensitivity', 'Road Mask Controls', 12, 50, self.nothing)\n",
    "        cv2.createTrackbar('NMS Threshold', 'Road Mask Controls', 30, 100, self.nothing)\n",
    "    \n",
    "    def apply_temporal_filtering(self, mask):\n",
    "            \"\"\"\n",
    "            Smooth the mask over time using the temporal buffer.\n",
    "            \"\"\"\n",
    "            self.temporal_buffer.append(mask)\n",
    "            combined_mask = np.sum(self.temporal_buffer, axis=0) / len(self.temporal_buffer)\n",
    "            return (combined_mask > 128).astype(np.uint8) * 255  # Threshold to binarize the mask\n",
    "    \n",
    "    def apply_enhanced_mask(self, frame, road_mask):\n",
    "        \"\"\"\n",
    "        Apply enhanced masking techniques to better isolate vehicles\n",
    "        \"\"\"\n",
    "        # Get foreground mask from MOG2\n",
    "        fg_mask = self.mog.apply(frame)\n",
    "        \n",
    "        # Convert frame to grayscale for additional processing\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply adaptive thresholding to handle varying lighting\n",
    "        thresh = cv2.adaptiveThreshold(\n",
    "            gray, 255,\n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY_INV, 11, 2\n",
    "        )\n",
    "        \n",
    "        # Edge detection to highlight vehicle boundaries\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "        \n",
    "        # Combine edges with threshold\n",
    "        combined = cv2.bitwise_or(thresh, edges)\n",
    "        \n",
    "        # Create motion mask\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        motion_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "        motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        # Combine motion with edges/threshold\n",
    "        enhanced_mask = cv2.bitwise_and(combined, motion_mask)\n",
    "        \n",
    "        # Apply road mask\n",
    "        final_mask = cv2.bitwise_and(enhanced_mask, enhanced_mask, mask=road_mask)\n",
    "        \n",
    "        # Clean up noise\n",
    "        final_mask = cv2.medianBlur(final_mask, 3)\n",
    "        final_mask = cv2.morphologyEx(final_mask, cv2.MORPH_CLOSE, \n",
    "                                    np.ones((5,5), np.uint8))\n",
    "        \n",
    "        return final_mask\n",
    "\n",
    "    def nothing(self, x):\n",
    "        pass\n",
    "\n",
    "    def get_random_color(self):\n",
    "        return (np.random.randint(0, 255),\n",
    "                np.random.randint(0, 255),\n",
    "                np.random.randint(0, 255))\n",
    "\n",
    "    def is_point_in_frame(self, point):\n",
    "        if self.frame_dimensions is None:\n",
    "            return True\n",
    "        \n",
    "        x, y = point\n",
    "        width, height = self.frame_dimensions\n",
    "        return (-self.margin <= x <= width + self.margin and \n",
    "                -self.margin <= y <= height + self.margin)\n",
    "\n",
    "    def is_point_on_road(self, point, road_mask):\n",
    "        x, y = point\n",
    "        if not self.is_point_in_frame((x, y)):\n",
    "            return False\n",
    "        \n",
    "        if y >= road_mask.shape[0] or x >= road_mask.shape[1] or x < 0 or y < 0:\n",
    "            return False\n",
    "            \n",
    "        return road_mask[y, x] > 0\n",
    "\n",
    "    def cleanup_tracks(self, current_frame, road_mask):\n",
    "        active_tracks = {}\n",
    "        active_colors = {}\n",
    "        active_activity = {}\n",
    "        \n",
    "        for track_id, track in self.tracks.items():\n",
    "            if not track:\n",
    "                continue\n",
    "                \n",
    "            last_point = track[-1]\n",
    "            \n",
    "            if (current_frame - self.track_activity.get(track_id, 0) <= self.frames_until_cleanup and\n",
    "                self.is_point_in_frame(last_point) and\n",
    "                self.is_point_on_road(last_point, road_mask)):\n",
    "                active_tracks[track_id] = track\n",
    "                active_colors[track_id] = self.track_colors[track_id]\n",
    "                active_activity[track_id] = self.track_activity[track_id]\n",
    "        \n",
    "        self.tracks = active_tracks\n",
    "        self.track_colors = active_colors\n",
    "        self.track_activity = active_activity\n",
    "\n",
    "    def update_mask_parameters(self):\n",
    "        h_min = cv2.getTrackbarPos('Hue Min', 'Road Mask Controls')\n",
    "        h_max = cv2.getTrackbarPos('Hue Max', 'Road Mask Controls')\n",
    "        s_min = cv2.getTrackbarPos('Sat Min', 'Road Mask Controls')\n",
    "        s_max = cv2.getTrackbarPos('Sat Max', 'Road Mask Controls')\n",
    "        v_min = cv2.getTrackbarPos('Val Min', 'Road Mask Controls')\n",
    "        v_max = cv2.getTrackbarPos('Val Max', 'Road Mask Controls')\n",
    "        \n",
    "        self.lower_bound = np.array([h_min, s_min, v_min])\n",
    "        self.upper_bound = np.array([h_max, s_max, v_max])\n",
    "        \n",
    "        self.min_area = cv2.getTrackbarPos('Min Area', 'Road Mask Controls')\n",
    "        dilate_size = cv2.getTrackbarPos('Dilate', 'Road Mask Controls')\n",
    "        self.dilate_kernel = np.ones((dilate_size, dilate_size), np.uint8)\n",
    "        \n",
    "        self.min_contour_area = cv2.getTrackbarPos('Min Vehicle Size', 'Road Mask Controls')\n",
    "        sensitivity = cv2.getTrackbarPos('Detection Sensitivity', 'Road Mask Controls')\n",
    "        self.mog.setVarThreshold(sensitivity)\n",
    "\n",
    "    def get_road_mask(self, frame):\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv, self.lower_bound, self.upper_bound)\n",
    "        \n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((5,5),np.uint8))\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((5,5),np.uint8))\n",
    "        \n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        filtered_mask = np.zeros_like(mask)\n",
    "        \n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) > self.min_area:\n",
    "                cv2.drawContours(filtered_mask, [contour], -1, 255, -1)\n",
    "        \n",
    "        filtered_mask = cv2.dilate(filtered_mask, self.dilate_kernel, iterations=1)\n",
    "        return filtered_mask\n",
    "\n",
    "    def find_closest_track(self, point):\n",
    "        min_dist = float('inf')\n",
    "        closest_id = None\n",
    "        \n",
    "        for track_id, track in self.tracks.items():\n",
    "            if track:\n",
    "                last_point = track[-1]\n",
    "                dist = np.sqrt((point[0] - last_point[0])**2 + \n",
    "                             (point[1] - last_point[1])**2)\n",
    "                if dist < min_dist and dist < self.max_tracking_distance:\n",
    "                    min_dist = dist\n",
    "                    closest_id = track_id\n",
    "        return closest_id\n",
    "\n",
    "    def process_detections(self, contours):\n",
    "        boxes = []\n",
    "        scores = []\n",
    "        centroids = []\n",
    "        \n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > self.min_contour_area:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                aspect_ratio = float(w)/h\n",
    "                \n",
    "                if 0.4 < aspect_ratio < 2.5:\n",
    "                    area_score = min(area / 2000.0, 1.0)\n",
    "                    aspect_score = 1.0 - abs(1.5 - aspect_ratio) / 1.5\n",
    "                    confidence = (area_score + aspect_score) / 2.0\n",
    "                    \n",
    "                    if confidence > self.detection_confidence_threshold:\n",
    "                        boxes.append([x, y, w, h])\n",
    "                        scores.append(confidence)\n",
    "                        centroids.append((int(x + w/2), int(y + h/2)))\n",
    "        \n",
    "        if boxes:\n",
    "            nms_threshold = cv2.getTrackbarPos('NMS Threshold', 'Road Mask Controls') / 100.0\n",
    "            keep_indices = non_max_suppression(boxes, scores, nms_threshold)\n",
    "            \n",
    "            filtered_boxes = [boxes[i] for i in keep_indices]\n",
    "            filtered_scores = [scores[i] for i in keep_indices]\n",
    "            filtered_centroids = [centroids[i] for i in keep_indices]\n",
    "            \n",
    "            return filtered_boxes, filtered_scores, filtered_centroids\n",
    "        \n",
    "        return [], [], []\n",
    "\n",
    "   \n",
    "    def process_frame(self, frame, frame_count):\n",
    "            if self.frame_dimensions is None:\n",
    "                self.frame_dimensions = (frame.shape[1], frame.shape[0])\n",
    "                \n",
    "            self.update_mask_parameters()\n",
    "            road_mask = self.get_road_mask(frame)\n",
    "            road_mask = self.apply_temporal_filtering(road_mask)\n",
    "            \n",
    "            self.cleanup_tracks(frame_count, road_mask)\n",
    "            \n",
    "            fg_mask = self.apply_enhanced_mask(frame, road_mask)\n",
    "            \n",
    "            contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            boxes, scores, centroids = self.process_detections(contours)\n",
    "            \n",
    "            for box, score, centroid in zip(boxes, scores, centroids):\n",
    "                if self.is_point_on_road(centroid, road_mask):\n",
    "                    track_id = self.find_closest_track(centroid)\n",
    "                    \n",
    "                    if track_id is None:\n",
    "                        track_id = self.next_track_id\n",
    "                        self.next_track_id += 1\n",
    "                        self.tracks[track_id] = deque(maxlen=self.max_trace_length)\n",
    "                        self.track_colors[track_id] = self.get_random_color()\n",
    "                    \n",
    "                    self.tracks[track_id].append(centroid)\n",
    "                    self.track_activity[track_id] = frame_count\n",
    "                    \n",
    "                    # Draw bounding box and confidence score\n",
    "                    x, y, w, h = box\n",
    "                    color = self.track_colors[track_id]\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                    \n",
    "                    # Draw vehicle ID and confidence score\n",
    "                    text = f'ID:{track_id} ({score:.2f})'\n",
    "                    text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
    "                    \n",
    "                    # Draw background rectangle for text\n",
    "                    cv2.rectangle(frame, \n",
    "                                (x, y - text_size[1] - 10), \n",
    "                                (x + text_size[0], y), \n",
    "                                color, \n",
    "                                -1)\n",
    "                    \n",
    "                    # Draw text in white for better visibility\n",
    "                    cv2.putText(frame, text, (x, y-5), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            \n",
    "            # Draw tracking trails\n",
    "            for track_id, track in self.tracks.items():\n",
    "                points = list(track)\n",
    "                if len(points) >= 2:\n",
    "                    color = self.track_colors[track_id]\n",
    "                    # Draw trail lines with fading effect\n",
    "                    for i in range(1, len(points)):\n",
    "                        alpha = float(i) / len(points)\n",
    "                        thickness = int(alpha * 3) + 1\n",
    "                        cv2.line(frame, points[i-1], points[i],\n",
    "                                tuple(int(c * alpha) for c in color), thickness)\n",
    "                    \n",
    "                    # Draw current position marker\n",
    "                    cv2.circle(frame, points[-1], 6, color, -1)\n",
    "                    cv2.circle(frame, points[-1], 8, color, 2)\n",
    "            \n",
    "            road_overlay = frame.copy()\n",
    "            road_overlay[road_mask == 0] = [0, 0, 0]\n",
    "            frame = cv2.addWeighted(frame, 0.7, road_overlay, 0.3, 0)\n",
    "            \n",
    "            return frame, road_mask, fg_mask\n",
    "\n",
    "\n",
    "\n",
    "    def process_video(self, video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open video\")\n",
    "            return\n",
    "        \n",
    "        frame_count = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            processed_frame, road_mask, fg_mask = self.process_frame(frame, frame_count)\n",
    "            \n",
    "            cv2.imshow('Road Mask', road_mask)\n",
    "            cv2.imshow('Foreground Mask', fg_mask)\n",
    "            cv2.imshow('Tracking', processed_frame)\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "tracker = VideoProcessor()\n",
    "tracker.process_video('Images/traffic.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motiondetection-LHEXs6Hk-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
